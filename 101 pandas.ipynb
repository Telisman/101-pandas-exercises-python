{
 "cells": [
  {
   "attachments": {
    "images.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e1db15c5",
   "metadata": {},
   "source": [
    "![images.png](attachment:images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6392e",
   "metadata": {},
   "source": [
    "# Challenge your Logical  Pandas Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbde7d0",
   "metadata": {},
   "source": [
    "101 questions to help you improve your analysis skills with jupyter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9cb32",
   "metadata": {},
   "source": [
    "1. How to import pandas and check the version?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bfc9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30fbda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : e8093ba372f9adfe79439d90fe74b0b5b6dea9d6\n",
      "python           : 3.10.5.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.19044\n",
      "machine          : AMD64\n",
      "processor        : AMD64 Family 23 Model 8 Stepping 2, AuthenticAMD\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : Serbian (Latin)_Serbia.1252\n",
      "\n",
      "pandas           : 1.4.3\n",
      "numpy            : 1.23.0\n",
      "pytz             : 2022.1\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 58.1.0\n",
      "pip              : 22.1.2\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : 4.9.1\n",
      "html5lib         : None\n",
      "pymysql          : 1.0.2\n",
      "psycopg2         : None\n",
      "jinja2           : 3.1.2\n",
      "IPython          : 8.4.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.11.1\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : None\n",
      "gcsfs            : None\n",
      "markupsafe       : 2.1.1\n",
      "matplotlib       : None\n",
      "numba            : None\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : 3.0.10\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : None\n",
      "snappy           : None\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : 2022.3.0\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648de2ec",
   "metadata": {},
   "source": [
    "## 2. How to create a series from a list, numpy array and dict?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe11db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'e', 'd', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0eda8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9f50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "1     b\n",
      "2     c\n",
      "3     e\n",
      "4     d\n",
      "5     f\n",
      "6     g\n",
      "7     h\n",
      "8     i\n",
      "9     j\n",
      "10    k\n",
      "11    l\n",
      "12    m\n",
      "13    n\n",
      "14    o\n",
      "15    p\n",
      "16    q\n",
      "17    r\n",
      "18    s\n",
      "19    t\n",
      "20    u\n",
      "21    v\n",
      "22    w\n",
      "23    x\n",
      "24    y\n",
      "25    z\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd5c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db9c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "myarr = np.arange(26)\n",
    "print(myarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42fc45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(myarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9395369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      2\n",
      "3      3\n",
      "4      4\n",
      "5      5\n",
      "6      6\n",
      "7      7\n",
      "8      8\n",
      "9      9\n",
      "10    10\n",
      "11    11\n",
      "12    12\n",
      "13    13\n",
      "14    14\n",
      "15    15\n",
      "16    16\n",
      "17    17\n",
      "18    18\n",
      "19    19\n",
      "20    20\n",
      "21    21\n",
      "22    22\n",
      "23    23\n",
      "24    24\n",
      "25    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738342f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = dict(zip(mylist, myarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7c804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'e': 3, 'd': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "print(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525b63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     0\n",
      "b     1\n",
      "c     2\n",
      "e     3\n",
      "d     4\n",
      "f     5\n",
      "g     6\n",
      "h     7\n",
      "i     8\n",
      "j     9\n",
      "k    10\n",
      "l    11\n",
      "m    12\n",
      "n    13\n",
      "o    14\n",
      "p    15\n",
      "q    16\n",
      "r    17\n",
      "s    18\n",
      "t    19\n",
      "u    20\n",
      "v    21\n",
      "w    22\n",
      "x    23\n",
      "y    24\n",
      "z    25\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(mydict)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436fadb7",
   "metadata": {},
   "source": [
    "## 3. How to convert the index of a series into a column of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d428ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81056376",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860e8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "1     b\n",
      "2     c\n",
      "3     e\n",
      "4     d\n",
      "5     f\n",
      "6     g\n",
      "7     h\n",
      "8     i\n",
      "9     j\n",
      "10    k\n",
      "11    l\n",
      "12    m\n",
      "13    n\n",
      "14    o\n",
      "15    p\n",
      "16    q\n",
      "17    r\n",
      "18    s\n",
      "19    t\n",
      "20    u\n",
      "21    v\n",
      "22    w\n",
      "23    x\n",
      "24    y\n",
      "25    z\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(mylist)\n",
    "ser.to_frame()\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "072ad8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  0\n",
      "0      0  a\n",
      "1      1  b\n",
      "2      2  c\n",
      "3      3  e\n",
      "4      4  d\n"
     ]
    }
   ],
   "source": [
    "df = ser.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd7dad",
   "metadata": {},
   "source": [
    "## 4. How to combine many series to form a dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a348ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f52d9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0   a   0\n",
      "1   b   1\n",
      "2   c   2\n",
      "3   e   3\n",
      "4   d   4\n",
      "5   f   5\n",
      "6   g   6\n",
      "7   h   7\n",
      "8   i   8\n",
      "9   j   9\n",
      "10  k  10\n",
      "11  l  11\n",
      "12  m  12\n",
      "13  n  13\n",
      "14  o  14\n",
      "15  p  15\n",
      "16  q  16\n",
      "17  r  17\n",
      "18  s  18\n",
      "19  t  19\n",
      "20  u  20\n",
      "21  v  21\n",
      "22  w  22\n",
      "23  x  23\n",
      "24  y  24\n",
      "25  z  25\n"
     ]
    }
   ],
   "source": [
    "df=pd.concat([ser1,ser2],axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04badc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  a  0\n",
      "1  b  1\n",
      "2  c  2\n",
      "3  e  3\n",
      "4  d  4\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04350cac",
   "metadata": {},
   "source": [
    "## How to assign name to the series’ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21e4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf222305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1     b\n",
       "2     c\n",
       "3     e\n",
       "4     d\n",
       "5     f\n",
       "6     g\n",
       "7     h\n",
       "8     i\n",
       "9     j\n",
       "10    k\n",
       "11    l\n",
       "12    m\n",
       "13    n\n",
       "14    o\n",
       "15    p\n",
       "16    q\n",
       "17    r\n",
       "18    s\n",
       "19    t\n",
       "20    u\n",
       "21    v\n",
       "22    w\n",
       "23    x\n",
       "24    y\n",
       "25    z\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.rename(\"alphabets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab49962",
   "metadata": {},
   "source": [
    "6. How to get the items of series A not present in series B?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d72f37",
   "metadata": {},
   "source": [
    "From ser1 remove items present in ser2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3122bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abcef922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "res = ser1[~ser1.isin(ser2)]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca867ae",
   "metadata": {},
   "source": [
    "## 7. How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd611a",
   "metadata": {},
   "source": [
    "Get all items of ser1 and ser2 not common to both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c1e963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e4a446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "union = pd.Series(np.union1d(ser1, ser2)) #combine to series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54e1ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = pd.Series(np.intersect1d(ser1, ser2))# intersection of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf109e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "5    6\n",
      "6    7\n",
      "7    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "notcommonseries = union[~union.isin(intersect)] # uncommon elements in both the series \n",
    "print(notcommonseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223ed4f",
   "metadata": {},
   "source": [
    "## 8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "132cb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25834320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     15.688437\n",
      "1      4.806242\n",
      "2     12.622296\n",
      "3      8.522431\n",
      "4     15.150375\n",
      "5      5.321725\n",
      "6     18.881260\n",
      "7      9.664941\n",
      "8      8.841973\n",
      "9      9.087968\n",
      "10    12.544047\n",
      "11     2.764899\n",
      "12    10.506380\n",
      "13     3.526115\n",
      "14    10.918010\n",
      "15    12.505226\n",
      "16    21.839864\n",
      "17    -5.410442\n",
      "18    17.295279\n",
      "19    11.904612\n",
      "20    13.036135\n",
      "21    15.988686\n",
      "22     4.746463\n",
      "23    15.207253\n",
      "24     7.164257\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0414424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.4104419   7.1642571  10.9180104  15.15037529 21.83986399]\n"
     ]
    }
   ],
   "source": [
    "result = np.percentile(ser, q=[0, 25, 50, 75, 100])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5e5c6",
   "metadata": {},
   "source": [
    "\n",
    "# 9. How to get frequency counts of unique items of a series?\n",
    "Calculte the frequency counts of each unique value ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33196784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     d\n",
      "1     c\n",
      "2     f\n",
      "3     d\n",
      "4     g\n",
      "5     e\n",
      "6     d\n",
      "7     a\n",
      "8     a\n",
      "9     e\n",
      "10    e\n",
      "11    e\n",
      "12    f\n",
      "13    h\n",
      "14    b\n",
      "15    b\n",
      "16    d\n",
      "17    f\n",
      "18    d\n",
      "19    e\n",
      "20    b\n",
      "21    d\n",
      "22    h\n",
      "23    e\n",
      "24    d\n",
      "25    d\n",
      "26    h\n",
      "27    g\n",
      "28    c\n",
      "29    f\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb7c5e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    8\n",
       "e    6\n",
       "f    4\n",
       "h    3\n",
       "b    3\n",
       "c    2\n",
       "g    2\n",
       "a    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e730b2",
   "metadata": {},
   "source": [
    "## 10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n",
    "From ser, keep the top 2 most frequent items as it is and replace everything else as ‘Other’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ccb05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e9246a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Other\n",
      "1     Other\n",
      "2         2\n",
      "3     Other\n",
      "4         2\n",
      "5         2\n",
      "6         2\n",
      "7     Other\n",
      "8         2\n",
      "9     Other\n",
      "10    Other\n",
      "11    Other\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "result = ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e61f27",
   "metadata": {},
   "source": [
    "## 11. How to bin a numeric series to 10 groups of equal size?\n",
    "Bin the series ser into 10 equal deciles and replace the values with the bin name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4d4ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.random(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1b45120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8th\n",
       "1     4th\n",
       "2     2nd\n",
       "3    10th\n",
       "4     8th\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805adfb",
   "metadata": {},
   "source": [
    "# 12. How to convert a numpy array to a dataframe of given shape? \n",
    "Reshape the series ser into a dataframe with 7 rows and 5 columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0ec8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb659d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ser.values #counvort into arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dca07c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_arr = arr.reshape((7, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2640cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 1 2 4 5]\n",
      " [7 9 7 1 2]\n",
      " [3 4 1 7 7]\n",
      " [9 2 1 8 3]\n",
      " [5 8 2 9 1]\n",
      " [5 2 5 4 7]\n",
      " [7 6 3 3 7]]\n"
     ]
    }
   ],
   "source": [
    "print(reshaped_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0e2fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ser.values.reshape(7,5)) #into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18f36c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  9  1  2  4  5\n",
      "1  7  9  7  1  2\n",
      "2  3  4  1  7  7\n",
      "3  9  2  1  8  3\n",
      "4  5  8  2  9  1\n",
      "5  5  2  5  4  7\n",
      "6  7  6  3  3  7\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03923560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7d771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c595d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ba4a86",
   "metadata": {},
   "source": [
    "# 13. How to find the positions of numbers that are multiples of 3 from a series?\n",
    "Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b4c2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74409a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where(ser % 3==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb51860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([6], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da98b5",
   "metadata": {},
   "source": [
    "14. How to extract items at given positions from a series?\n",
    "From ser, extract the items at positions in list pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f669cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11a8b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ser.take(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7854831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "4     e\n",
      "8     i\n",
      "14    o\n",
      "20    u\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f2d7e",
   "metadata": {},
   "source": [
    "## 15. How to stack two series vertically and horizontally ?\n",
    "Stack ser1 and ser2 vertically and horizontally (to form a dataframe).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7452aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2ddf9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ser1, ser2], axis = 1)#Horizontally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47c10a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "171e04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ser1, ser2], axis = 0)#Vertically \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e965aeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5bd50",
   "metadata": {},
   "source": [
    "## 16. How to get the positions of items of series A in another series B?\n",
    "Get the positions of items of ser2 in ser1 as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a66ba49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44287537",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b32996f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 0, 8]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c115d85",
   "metadata": {},
   "source": [
    "## 17. How to compute the mean squared error on a truth and predicted series?\n",
    "Compute the mean squared error of truth and pred series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "464d982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52b4aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = np.square(np.subtract(truth,pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51751ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2656014623004312\n"
     ]
    }
   ],
   "source": [
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb13e8d",
   "metadata": {},
   "source": [
    "18. How to convert the first character of each element in a series to uppercase?\n",
    "Change the first character of each word to upper case in each word of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63720eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb89a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = ser.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a1a54ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     How\n",
      "1      To\n",
      "2    Kick\n",
      "3    Ass?\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252dd4fb",
   "metadata": {},
   "source": [
    "19. How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34865613",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a0e1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = ser.map(lambda calc: len(calc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a839ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    2\n",
      "2    4\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7385e",
   "metadata": {},
   "source": [
    "20. How to compute difference of differences between consequtive numbers of a series?\n",
    "Difference of differences between the consequtive numbers of ser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b96e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1dcd343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a376cb",
   "metadata": {},
   "source": [
    "## 21. How to convert a series of date-strings to a timeseries?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a14ddd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187c716",
   "metadata": {},
   "source": [
    "## 22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n",
    "Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11d5b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "from dateutil.parser import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61f0ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_ts = ser.map(lambda x: parse(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a298e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Davor\\AppData\\Local\\Temp\\ipykernel_17648\\4121860575.py:2: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n"
     ]
    }
   ],
   "source": [
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a389d",
   "metadata": {},
   "source": [
    "## 23. How to convert year-month string to dates corresponding to the 4th day of the month?\n",
    "Change ser to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ed615fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ce891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ser.map(lambda d: parse('4 ' + d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0682cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-04\n",
      "1   2011-02-04\n",
      "2   2012-03-04\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53f593",
   "metadata": {},
   "source": [
    "24. How to filter words that contain atleast 2 vowels from a series?\n",
    "From ser, extract words that contain atleast 2 vowels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "115825d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "from collections import Counter #be sure to import the library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "433e521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d335f",
   "metadata": {},
   "source": [
    "## 25. How to filter valid emails from a series?\n",
    "Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "07fa5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b8acee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex     #be sure to import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9c2354af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_result = emails.map(lambda i: bool(regex.match(pattern, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3bd414b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    rameses@egypt.com\n",
      "2            matt@t.co\n",
      "3    narendra@modi.com\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(emails[mapped_result])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7080317",
   "metadata": {},
   "source": [
    "## 26. How to get the mean of a series grouped by another series?\n",
    "Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c86bc762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['apple', 'apple', 'banana', 'apple', 'banana', 'banana', 'apple', 'apple', 'banana', 'carrot']\n"
     ]
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c1b6d",
   "metadata": {},
   "source": [
    "# 27. How to compute the euclidean distance between two series?\n",
    "\n",
    "Compute the euclidean distance between series (points) p and q, without using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900eb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8247b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.sum([(a * a) for a in p])\n",
    "p2 = np.sum([(b * b) for b in q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5125489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = -1 * np.sum([(2 * a*b) for (a, b) in zip(p, q)])\n",
    "dist = np.sqrt(np.sum(p1 + p2 + p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1859b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series 1: 0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "5     6\n",
      "6     7\n",
      "7     8\n",
      "8     9\n",
      "9    10\n",
      "dtype: int64\n",
      "Series 2: 0    10\n",
      "1     9\n",
      "2     8\n",
      "3     7\n",
      "4     6\n",
      "5     5\n",
      "6     4\n",
      "7     3\n",
      "8     2\n",
      "9     1\n",
      "dtype: int64\n",
      "Euclidean distance between two series is: 18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "print(\"Series 1:\", p)\n",
    "print(\"Series 2:\", q)\n",
    "print(\"Euclidean distance between two series is:\", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c370c",
   "metadata": {},
   "source": [
    "# 28. How to find all the local maxima (or peaks) in a numeric series?\n",
    "Get the positions of peaks (values surrounded by smaller values on both sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93198f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ceac1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb230c",
   "metadata": {},
   "source": [
    "# 29. How to replace missing spaces in a string with the least frequent character?\n",
    "Replace the spaces in my_str with the least frequent character.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ca3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = 'dbc deb abed gade'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b712aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list(my_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6be5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_freq = ser.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a46597",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_freq = element_freq.dropna().index[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4027f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbcgdebgabedggade\n"
     ]
    }
   ],
   "source": [
    "result = \"\".join(ser.replace(' ',current_freq))\n",
    " \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740b007",
   "metadata": {},
   "source": [
    "\n",
    "# 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccb40bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    9\n",
       "2000-01-08    9\n",
       "2000-01-15    4\n",
       "2000-01-22    8\n",
       "2000-01-29    8\n",
       "2000-02-05    1\n",
       "2000-02-12    5\n",
       "2000-02-19    3\n",
       "2000-02-26    6\n",
       "2000-03-04    3\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c9984",
   "metadata": {},
   "source": [
    "\n",
    "# 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n",
    "ser has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c5a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e33764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02     1.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04    10.0\n",
       "2000-01-05    10.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ab444d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.resample('D').bfill()  \n",
    "ser.resample('D').bfill().ffill()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c5b8a",
   "metadata": {},
   "source": [
    "# 32. How to compute the autocorrelations of a numeric series?\n",
    "Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd16930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f775b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8989f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19, -0.1, 0.05, 0.01, 0.68, -0.02, 0.02, 0.44, -0.07, 0.09]\n"
     ]
    }
   ],
   "source": [
    "print(autocorrelations[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da348a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag having highest correlation:  5\n"
     ]
    }
   ],
   "source": [
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec25075",
   "metadata": {},
   "source": [
    "# 33. How to import only every nth row from a csv file to create a dataframe?\n",
    "Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "721bdc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9351ee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crim    zn  indus  chas    nox     rm    age     dis   rad    tax  \\\n",
      "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
      "50    0.08873  21.0   5.64   0.0  0.439  5.963   45.7  6.8147   4.0  243.0   \n",
      "100   0.14866   0.0   8.56   0.0  0.520  6.727   79.9  2.7778   5.0  384.0   \n",
      "150   1.65660   0.0  19.58   0.0  0.871  6.122   97.3  1.6180   5.0  403.0   \n",
      "200   0.01778  95.0   1.47   0.0  0.403  7.135   13.9  7.6534   3.0  402.0   \n",
      "250   0.14030  22.0   5.86   0.0  0.431  6.487   13.0  7.3967   7.0  330.0   \n",
      "300   0.04417  70.0   2.24   0.0  0.400  6.871   47.4  7.8278   5.0  358.0   \n",
      "350   0.06211  40.0   1.25   0.0  0.429  6.490   44.4  8.7921   1.0  335.0   \n",
      "400  25.04610   0.0  18.10   0.0  0.693  5.987  100.0  1.5888  24.0  666.0   \n",
      "450   6.71772   0.0  18.10   0.0  0.713  6.749   92.6  2.3236  24.0  666.0   \n",
      "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "0       15.3  396.90   4.98  24.0  \n",
      "50      16.8  395.56  13.45  19.7  \n",
      "100     20.9  394.76   9.42  27.5  \n",
      "150     14.7  372.80  14.10  21.5  \n",
      "200     17.0  384.30   4.45  32.9  \n",
      "250     19.1  396.28   5.90  24.4  \n",
      "300     14.8  390.86   6.07  24.8  \n",
      "350     19.7  396.90   5.98  22.9  \n",
      "400     20.2  396.90  26.77   5.6  \n",
      "450     20.2    0.32  17.44  13.4  \n",
      "500     19.2  396.90  14.33  16.8  \n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb873cc4",
   "metadata": {},
   "source": [
    "# 34. How to change column values when importing csv to a dataframe?\n",
    "Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "410dd8cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BostonHousing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBostonHousing.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m      4\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BostonHousing.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('BostonHousing.csv', 'r') as f: #inser file and read\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "        out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0470d7fa",
   "metadata": {},
   "source": [
    "\n",
    "# 35. How to create a dataframe with rows as strides from a given series?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a09dc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(range(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5110a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd41b9",
   "metadata": {},
   "source": [
    "\n",
    "# 36. How to import only specified columns from a csv file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1ac2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fc16f",
   "metadata": {},
   "source": [
    "# 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n",
    "Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a515cfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_dtype_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dtype_counts\u001b[49m())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m     11\u001b[0m df_stats \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_dtype_counts'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df.get_dtype_counts())\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "df_stats = df.describe()\n",
    "\n",
    "\n",
    "\n",
    "df_arr = df.values\n",
    "\n",
    "df_list = df.values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726509f",
   "metadata": {},
   "source": [
    "# 38. How to extract the row and column number of a particular cell with given criterion?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb38cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef965754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>300E</td>\n",
       "      <td>Midsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Manufacturer Model     Type\n",
       "58  Mercedes-Benz  300E  Midsize"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "529c191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = np.where(df.values == np.max(df.Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5f0241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f50ec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'get_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mat[row[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m(row[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_value'"
     ]
    }
   ],
   "source": [
    "df.at[row[0], 'Price']\n",
    "df.get_value(row[0], 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862cff1a",
   "metadata": {},
   "source": [
    "# 39. How to rename a specific columns in a dataframe?\n",
    "Rename the column Type as CarType in df and replace the ‘.’ in column names with ‘_’.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70439a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n",
      "       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n",
      "       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd5e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"Type\": \"CarType\"}, \n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1172079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min.Price', 'Price', 'Max.Price',\n",
      "       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n",
      "       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee12eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns) #relace . with _"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbcaf65",
   "metadata": {},
   "source": [
    "# 40. How to check if a dataframe has any missing values?\n",
    "Check if df has any missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a4ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d7636d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
      "0         Acura  Integra    Small       12.9   15.9       18.8      25.0   \n",
      "1           NaN   Legend  Midsize       29.2   33.9       38.7      18.0   \n",
      "2          Audi       90  Compact       25.9   29.1       32.3      20.0   \n",
      "3          Audi      100  Midsize        NaN   37.7       44.6      19.0   \n",
      "4           BMW     535i  Midsize        NaN   30.0        NaN      22.0   \n",
      "..          ...      ...      ...        ...    ...        ...       ...   \n",
      "88   Volkswagen  Eurovan      Van       16.6   19.7       22.7      17.0   \n",
      "89   Volkswagen   Passat  Compact       17.6   20.0       22.4      21.0   \n",
      "90   Volkswagen  Corrado   Sporty       22.9   23.3       23.7      18.0   \n",
      "91        Volvo      240  Compact       21.8   22.7       23.5      21.0   \n",
      "92          NaN      850  Midsize       24.8   26.7       28.5      20.0   \n",
      "\n",
      "    MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n",
      "0          31.0                None      Front  ...        5.0   177.0   \n",
      "1          25.0  Driver & Passenger      Front  ...        5.0   195.0   \n",
      "2          26.0         Driver only      Front  ...        5.0   180.0   \n",
      "3          26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n",
      "4          30.0                 NaN       Rear  ...        4.0   186.0   \n",
      "..          ...                 ...        ...  ...        ...     ...   \n",
      "88         21.0                None      Front  ...        7.0   187.0   \n",
      "89         30.0                None      Front  ...        5.0   180.0   \n",
      "90         25.0                None      Front  ...        4.0   159.0   \n",
      "91         28.0         Driver only       Rear  ...        5.0   190.0   \n",
      "92         28.0  Driver & Passenger      Front  ...        5.0   184.0   \n",
      "\n",
      "    Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n",
      "0       102.0   68.0         37.0           26.5           NaN  2705.0   \n",
      "1       115.0   71.0         38.0           30.0          15.0  3560.0   \n",
      "2       102.0   67.0         37.0           28.0          14.0  3375.0   \n",
      "3       106.0    NaN         37.0           31.0          17.0  3405.0   \n",
      "4       109.0   69.0         39.0           27.0          13.0  3640.0   \n",
      "..        ...    ...          ...            ...           ...     ...   \n",
      "88      115.0   72.0         38.0           34.0           NaN  3960.0   \n",
      "89      103.0   67.0         35.0           31.5          14.0  2985.0   \n",
      "90       97.0   66.0         36.0           26.0          15.0  2810.0   \n",
      "91      104.0   67.0         37.0           29.5          14.0  2985.0   \n",
      "92      105.0   69.0         38.0           30.0          15.0  3245.0   \n",
      "\n",
      "     Origin                Make  \n",
      "0   non-USA       Acura Integra  \n",
      "1   non-USA        Acura Legend  \n",
      "2   non-USA             Audi 90  \n",
      "3   non-USA            Audi 100  \n",
      "4   non-USA            BMW 535i  \n",
      "..      ...                 ...  \n",
      "88      NaN  Volkswagen Eurovan  \n",
      "89  non-USA   Volkswagen Passat  \n",
      "90  non-USA  Volkswagen Corrado  \n",
      "91  non-USA           Volvo 240  \n",
      "92  non-USA           Volvo 850  \n",
      "\n",
      "[93 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aae4dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9976d467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b414f0",
   "metadata": {},
   "source": [
    "# 41. How to count the number of missing values in each column?\n",
    "Count the number of missing values in each column of df. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "304cc129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f13f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff01456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missings_each_col.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1998f",
   "metadata": {},
   "source": [
    "# 42. How to replace missing values of multiple numeric columns with the mean?\n",
    "Replace missing values in Min.Price and Max.Price columns with their respective mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea362caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c088d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465bab5",
   "metadata": {},
   "source": [
    "# 43. How to use apply function on existing columns with global variables as additional arguments?\n",
    "In df, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "affaefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b5ab552",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2d7376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Min.Price': <function nanmean at 0x00000247F36348B0>, 'Max.Price': <function nanmedian at 0x00000247F3634C10>}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55984335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6becd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
      "0         Acura  Integra    Small  12.900000   15.9      18.80      25.0   \n",
      "1           NaN   Legend  Midsize  29.200000   33.9      38.70      18.0   \n",
      "2          Audi       90  Compact  25.900000   29.1      32.30      20.0   \n",
      "3          Audi      100  Midsize  17.118605   37.7      44.60      19.0   \n",
      "4           BMW     535i  Midsize  17.118605   30.0      19.15      22.0   \n",
      "..          ...      ...      ...        ...    ...        ...       ...   \n",
      "88   Volkswagen  Eurovan      Van  16.600000   19.7      22.70      17.0   \n",
      "89   Volkswagen   Passat  Compact  17.600000   20.0      22.40      21.0   \n",
      "90   Volkswagen  Corrado   Sporty  22.900000   23.3      23.70      18.0   \n",
      "91        Volvo      240  Compact  21.800000   22.7      23.50      21.0   \n",
      "92          NaN      850  Midsize  24.800000   26.7      28.50      20.0   \n",
      "\n",
      "    MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n",
      "0          31.0                None      Front  ...        5.0   177.0   \n",
      "1          25.0  Driver & Passenger      Front  ...        5.0   195.0   \n",
      "2          26.0         Driver only      Front  ...        5.0   180.0   \n",
      "3          26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n",
      "4          30.0                 NaN       Rear  ...        4.0   186.0   \n",
      "..          ...                 ...        ...  ...        ...     ...   \n",
      "88         21.0                None      Front  ...        7.0   187.0   \n",
      "89         30.0                None      Front  ...        5.0   180.0   \n",
      "90         25.0                None      Front  ...        4.0   159.0   \n",
      "91         28.0         Driver only       Rear  ...        5.0   190.0   \n",
      "92         28.0  Driver & Passenger      Front  ...        5.0   184.0   \n",
      "\n",
      "    Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n",
      "0       102.0   68.0         37.0           26.5           NaN  2705.0   \n",
      "1       115.0   71.0         38.0           30.0          15.0  3560.0   \n",
      "2       102.0   67.0         37.0           28.0          14.0  3375.0   \n",
      "3       106.0    NaN         37.0           31.0          17.0  3405.0   \n",
      "4       109.0   69.0         39.0           27.0          13.0  3640.0   \n",
      "..        ...    ...          ...            ...           ...     ...   \n",
      "88      115.0   72.0         38.0           34.0           NaN  3960.0   \n",
      "89      103.0   67.0         35.0           31.5          14.0  2985.0   \n",
      "90       97.0   66.0         36.0           26.0          15.0  2810.0   \n",
      "91      104.0   67.0         37.0           29.5          14.0  2985.0   \n",
      "92      105.0   69.0         38.0           30.0          15.0  3245.0   \n",
      "\n",
      "     Origin                Make  \n",
      "0   non-USA       Acura Integra  \n",
      "1   non-USA        Acura Legend  \n",
      "2   non-USA             Audi 90  \n",
      "3   non-USA            Audi 100  \n",
      "4   non-USA            BMW 535i  \n",
      "..      ...                 ...  \n",
      "88      NaN  Volkswagen Eurovan  \n",
      "89  non-USA   Volkswagen Passat  \n",
      "90  non-USA  Volkswagen Corrado  \n",
      "91  non-USA           Volvo 240  \n",
      "92  non-USA           Volvo 850  \n",
      "\n",
      "[93 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b3667",
   "metadata": {},
   "source": [
    "# 44. How to select a specific column from a dataframe as a dataframe instead of a series?\n",
    "Get the first column (a) in df as a dataframe (rather than as a Series).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7787d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58a0179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[['a']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cc314",
   "metadata": {},
   "source": [
    "# 45. How to change the order of columns of a dataframe?\n",
    "Actually 3 questions.\n",
    "\n",
    "In df, interchange columns 'a' and 'c'.\n",
    "\n",
    "Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f569907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a0d72c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d   e\n",
      "0   0   1   2   3   4\n",
      "1   5   6   7   8   9\n",
      "2  10  11  12  13  14\n",
      "3  15  16  17  18  19\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fdbf9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c   b   a   d   e\n",
       "0   2   1   0   3   4\n",
       "1   7   6   5   8   9\n",
       "2  12  11  10  13  14\n",
       "3  17  16  15  18  19"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[list('cbade')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "984b0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "\n",
    "df1 = switch_columns(df, 'a', 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eba8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c   b   a   d   e\n",
      "0   2   1   0   3   4\n",
      "1   7   6   5   8   9\n",
      "2  12  11  10  13  14\n",
      "3  17  16  15  18  19\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8785756e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c   d   e\n",
       "0   0   1   2   3   4\n",
       "1   5   6   7   8   9\n",
       "2  10  11  12  13  14\n",
       "3  15  16  17  18  19"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[sorted(df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01423fda",
   "metadata": {},
   "source": [
    "# 46. How to set the number of rows and columns displayed in the output?\n",
    "Change the pamdas display settings on printing the dataframe df it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38b4e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d09c137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce303a",
   "metadata": {},
   "source": [
    "# 47. How to format or suppress scientific notations in a pandas dataframe?\n",
    "Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7846124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09560572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0005\n",
      "1  0.0000\n",
      "2  0.1005\n",
      "3  0.0000\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296aade",
   "metadata": {},
   "source": [
    "# 48. How to format all the values in a dataframe as percentages?\n",
    "Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d89dc605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.6868\n",
      "1  0.5479\n",
      "2  0.9361\n",
      "3  0.8514\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "156ad8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d6978\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d6978_level0_col0\" class=\"col_heading level0 col0\" >random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d6978_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d6978_row0_col0\" class=\"data row0 col0\" >68.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6978_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d6978_row1_col0\" class=\"data row1 col0\" >54.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6978_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d6978_row2_col0\" class=\"data row2 col0\" >93.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6978_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d6978_row3_col0\" class=\"data row3 col0\" >85.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x247f6ec7c40>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = df.style.format({'random': '{0:.2%}'.format,})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6a427",
   "metadata": {},
   "source": [
    "# 49. How to filter every nth row in a dataframe?\n",
    "From df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b65df3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca051484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type  Min.Price   Price  ...  Rear.seat.room  \\\n",
      "0         Acura  Integra    Small    12.9000 15.9000  ...         26.5000   \n",
      "1           NaN   Legend  Midsize    29.2000 33.9000  ...         30.0000   \n",
      "2          Audi       90  Compact    25.9000 29.1000  ...         28.0000   \n",
      "3          Audi      100  Midsize        NaN 37.7000  ...         31.0000   \n",
      "4           BMW     535i  Midsize        NaN 30.0000  ...         27.0000   \n",
      "..          ...      ...      ...        ...     ...  ...             ...   \n",
      "88   Volkswagen  Eurovan      Van    16.6000 19.7000  ...         34.0000   \n",
      "89   Volkswagen   Passat  Compact    17.6000 20.0000  ...         31.5000   \n",
      "90   Volkswagen  Corrado   Sporty    22.9000 23.3000  ...         26.0000   \n",
      "91        Volvo      240  Compact    21.8000 22.7000  ...         29.5000   \n",
      "92          NaN      850  Midsize    24.8000 26.7000  ...         30.0000   \n",
      "\n",
      "    Luggage.room    Weight   Origin                Make  \n",
      "0            NaN 2705.0000  non-USA       Acura Integra  \n",
      "1        15.0000 3560.0000  non-USA        Acura Legend  \n",
      "2        14.0000 3375.0000  non-USA             Audi 90  \n",
      "3        17.0000 3405.0000  non-USA            Audi 100  \n",
      "4        13.0000 3640.0000  non-USA            BMW 535i  \n",
      "..           ...       ...      ...                 ...  \n",
      "88           NaN 3960.0000      NaN  Volkswagen Eurovan  \n",
      "89       14.0000 2985.0000  non-USA   Volkswagen Passat  \n",
      "90       15.0000 2810.0000  non-USA  Volkswagen Corrado  \n",
      "91       14.0000 2985.0000  non-USA           Volvo 240  \n",
      "92       15.0000 3245.0000  non-USA           Volvo 850  \n",
      "\n",
      "[93 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c7fc196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1916b",
   "metadata": {},
   "source": [
    "# 50. How to create a primary key index by combining relevant columns?\n",
    "\n",
    "\n",
    "In df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dad97b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fc65834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing') #fill mising values in col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6713dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
